{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "FWSnabY1S6lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Lavi Nigam](https://github.com/lavinigam-gcp) |"
      ],
      "metadata": {
        "id": "nPwbb4OdS7rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebooks:\n",
        "**goo.gle/io24-gemini-api**\n",
        "\n",
        "Google AI Cookbook:\n",
        "**goo.gle/google-ai-cookbook**\n",
        "\n",
        "Vertex AI Cookbook:\n",
        "**goo.gle/vertex-ai-cookbook**"
      ],
      "metadata": {
        "id": "bN8VxvT3WLZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What do we want to build?"
      ],
      "metadata": {
        "id": "YXoqP2KJpB-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "![](https://storage.googleapis.com/gemini-lavi-asset/img/output.png)"
      ],
      "metadata": {
        "id": "SEkEW1bIoqdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 - Google Cloud Vertex AI Gemini API"
      ],
      "metadata": {
        "id": "6RMTXdSRChy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Library installation # needs restarts\n",
        "! pip install --upgrade google-cloud-aiplatform\n",
        "! pip install PyPDF2"
      ],
      "metadata": {
        "id": "vOZVZgNJDCfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNDLW6CNA7dY"
      },
      "outputs": [],
      "source": [
        "# Authentication\n",
        "\n",
        "import sys\n",
        "from google.cloud import storage\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Define project information\n",
        "    PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "    LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "    BUCKET_NAME = \"gemini-lavi-asset\" # @param {type:\"string\"}\n",
        "    # Initialize Vertex AI\n",
        "    import vertexai\n",
        "\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "    # Initialize cloud storage\n",
        "    storage_client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = storage_client.bucket(BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Library\n",
        "from IPython.display import display, Markdown, Latex\n",
        "import vertexai.generative_models as genai\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import time\n",
        "from vertexai.generative_models import (\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    GenerationConfig,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold,\n",
        ")\n",
        "import PyPDF2\n",
        "from io import BytesIO\n",
        "from vertexai.preview.generative_models import Part\n",
        "from google.cloud import storage\n",
        "from io import BytesIO\n",
        "from datetime import datetime, timezone\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from IPython.display import display, Markdown, Latex\n",
        "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
        "from vertexai.generative_models import (\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    GenerationConfig,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold,\n",
        ")\n",
        "from typing import List\n",
        "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
        "from google.cloud import storage\n",
        "from io import BytesIO\n",
        "from rich import print as rich_print\n",
        "from rich.markdown import Markdown as rich_Markdown\n",
        "import pickle\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "metadata": {
        "id": "HrPf6V_1Sown"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Metadata & Index"
      ],
      "metadata": {
        "id": "n00F8_ChKFfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_15_pro_new = genai.GenerativeModel(\"gemini-1.5-pro-preview-0514\")\n",
        "gemini_15_flash = genai.GenerativeModel(\"gemini-1.5-flash-preview-0514\")"
      ],
      "metadata": {
        "id": "HSBt3axT3LN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helper Functions\n",
        "\n",
        "def get_gemini_response(model, generation_config=None,\n",
        "                        safety_settings=None,\n",
        "                        uri_path=None,mime_type=None, prompt=None):\n",
        "  if not generation_config:\n",
        "    generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 1,\n",
        "      \"top_p\": 0.95,\n",
        "    }\n",
        "\n",
        "  if not safety_settings:\n",
        "    safety_settings = {\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    }\n",
        "\n",
        "  uri = \"gs://\"+uri_path\n",
        "  file = genai.Part.from_uri(\n",
        "    mime_type=mime_type,\n",
        "    uri=uri\n",
        "    )\n",
        "  responses = model.generate_content([file, prompt],\n",
        "      generation_config=generation_config,\n",
        "      safety_settings=safety_settings,\n",
        "      stream=True,\n",
        "  )\n",
        "  final_response = []\n",
        "  for response in responses:\n",
        "    try:\n",
        "      final_response.append(response.text)\n",
        "    except ValueError:\n",
        "      # print(\"Something is blocked...\")\n",
        "      final_response.append(\"blocked\")\n",
        "\n",
        "  return \"\".join(final_response)\n",
        "\n",
        "def get_text_from_pdf(bucket):\n",
        "  extracted_text = []\n",
        "  # Iterate over all blobs (files) in the bucket\n",
        "  for blob in bucket.list_blobs():\n",
        "      if blob.name.startswith(\"production/\"):\n",
        "        if blob.name.lower().endswith('.pdf'):  # Check if the file is a PDF\n",
        "            # Download the PDF to a BytesIO object\n",
        "            pdf_content = BytesIO(blob.download_as_bytes())\n",
        "            try:\n",
        "                # Process the PDF using PyPDF2\n",
        "                pdf_reader = PyPDF2.PdfReader(pdf_content)\n",
        "                text = \"\"\n",
        "                pdf_data = []\n",
        "                text_type = \"/\".join(blob.name.split(\"/\")[1:-1])\n",
        "                filename = blob.name.split(\"/\")[-1]\n",
        "                for page_num in range(len(pdf_reader.pages)):\n",
        "                    page = pdf_reader.pages[page_num]\n",
        "                    text = page.extract_text()\n",
        "                    if text:\n",
        "                      pdf_data.append(\n",
        "                      {\n",
        "                          'text_type' : text_type,\n",
        "                          'gcs_path': \"gs://\"+blob.bucket.name+\"/\"+blob.name,\n",
        "                          'page_number': page_num+1,\n",
        "                          'text': text\n",
        "                      }\n",
        "                      )\n",
        "                extracted_text.extend(pdf_data)\n",
        "                # break\n",
        "            except:\n",
        "                print(f\"Warning: Could not read PDF file '{blob.name}' (might be encrypted or corrupted)\")\n",
        "  return pd.DataFrame(extracted_text)\n",
        "\n",
        "# 16-17 min\n",
        "def get_text_from_video(bucket, model, prompt, time_sleep=5):\n",
        "  video_metadata = []\n",
        "  for blob in bucket.list_blobs():\n",
        "      if blob.name.startswith(\"production/\"):\n",
        "        if blob.name.lower().endswith('.mp4'):\n",
        "          print(\"processing....\",blob.name)\n",
        "          video_type = \"/\".join(blob.name.split(\"/\")[1:-1])\n",
        "          gcs_path = \"/\".join(blob.id.split(\"/\")[:-1])\n",
        "          try:\n",
        "            video_description = get_gemini_response(uri_path=gcs_path,\n",
        "                                                    model=model,\n",
        "                                                    mime_type='video/mp4',\n",
        "                                                    prompt = prompt)\n",
        "            if video_description:\n",
        "              video_metadata.append(\n",
        "                  {\n",
        "                      'video_gcs': \"gs://\"+blob.bucket.name+\"/\"+blob.name,\n",
        "                      'video_type':video_type,\n",
        "                      'video_description': video_description\n",
        "                  }\n",
        "\n",
        "              )\n",
        "          except:\n",
        "            print(\"Something Failed........\")\n",
        "            video_metadata.append(\n",
        "                  {\n",
        "                      'video_gcs': \"gs://\"+blob.name,\n",
        "                      'video_type':video_type,\n",
        "                      'video_description': \"\"\n",
        "                  }\n",
        "\n",
        "              )\n",
        "          # print(\"sleeping......\")\n",
        "          time.sleep(time_sleep)\n",
        "          # break\n",
        "  return pd.DataFrame(video_metadata)\n",
        "\n",
        "# ~20 min\n",
        "def get_text_from_audio(bucket, model, prompt, time_sleep=5):\n",
        "  # Iterate over all blobs (files) in the bucket\n",
        "  audio_metadata = []\n",
        "  for blob in bucket.list_blobs():\n",
        "    if blob.name.startswith(\"production/\"):\n",
        "      if blob.name.lower().endswith('.mp3'):\n",
        "        print(\"processing....\",blob.name)\n",
        "        video_type = \"/\".join(blob.name.split(\"/\")[1:-1])\n",
        "        gcs_path = \"/\".join(blob.id.split(\"/\")[:-1])\n",
        "        # print(gcs_path)\n",
        "        try:\n",
        "          audio_description = get_gemini_response(uri_path=gcs_path,\n",
        "                                                  model=model,\n",
        "                                                  mime_type='audio/mpeg',\n",
        "                                                  prompt=prompt)\n",
        "          if audio_description:\n",
        "            audio_metadata.append(\n",
        "                {\n",
        "                    'audio_gcs': \"gs://\"+blob.bucket.name+\"/\"+blob.name,\n",
        "                    'audio_type':video_type,\n",
        "                    'audio_description': audio_description\n",
        "                }\n",
        "\n",
        "            )\n",
        "        except:\n",
        "          print(\"Something Failed........\")\n",
        "          audio_metadata.append(\n",
        "              {\n",
        "                  'audio_gcs': blob.name,\n",
        "                  'audio_type':video_type,\n",
        "                  'audio_description': \"\"\n",
        "              }\n",
        "\n",
        "          )\n",
        "        # print(\"sleeping......\")\n",
        "        time.sleep(time_sleep)\n",
        "        # break\n",
        "  return pd.DataFrame(audio_metadata)\n",
        "\n",
        "def split_text_into_chunks(df, text_column, chunk_size):\n",
        "    \"\"\"Splits text into chunks of specified size, preserving other column values.\"\"\"\n",
        "\n",
        "    # Create a list of new dataframes, one for each chunk\n",
        "    new_dfs = []\n",
        "    for _, row in df.iterrows():\n",
        "        text_chunks = [row[text_column][i:i + chunk_size] for i in range(0, len(row[text_column]), chunk_size)]\n",
        "        for chunk in text_chunks:\n",
        "            new_row = row.copy()  # Copy all other columns\n",
        "            new_row[text_column] = chunk\n",
        "            new_dfs.append(pd.DataFrame([new_row]))\n",
        "\n",
        "    return pd.concat(new_dfs, ignore_index=True)  # Combine into single dataframe\n",
        "\n",
        "def get_text_embeddings(\n",
        "    texts: List[str] = [\"banana muffins? \", \"banana bread? banana muffins?\"],\n",
        "    task: str = \"RETRIEVAL_DOCUMENT\",\n",
        "    model_name: str = \"textembedding-gecko@003\",\n",
        ") -> List[List[float]]:\n",
        "    # print(\"doing...\")\n",
        "    \"\"\"Embeds texts with a pre-trained, foundational model.\"\"\"\n",
        "    model = TextEmbeddingModel.from_pretrained(model_name)\n",
        "    inputs = [TextEmbeddingInput(text, task) for text in texts]\n",
        "    embeddings = model.get_embeddings(inputs)\n",
        "    return [embedding.values for embedding in embeddings][0]\n",
        "\n",
        "def backup_metadata_in_pickle(extracted_text,\n",
        "                              video_metadata,\n",
        "                              audio_metadata,\n",
        "                              index_db,\n",
        "                              output_path_with_name):\n",
        "  import pickle\n",
        "  data_to_save = {\n",
        "      \"extracted_text\": extracted_text,\n",
        "      \"video_metadata\": video_metadata,\n",
        "      \"audio_metadata\": audio_metadata,\n",
        "      \"index_db\": index_db\n",
        "  }\n",
        "  print(\"Backing up the metadata in: \",output_path_with_name+\".pkl\")\n",
        "  with open(f\"{output_path_with_name}.pkl\", \"wb\") as f:\n",
        "      pickle.dump(data_to_save,f)\n",
        "\n",
        "# def load_backuped_metadata(backup_path_with_name):\n",
        "#   import pickle\n",
        "#   import pandas as pd\n",
        "\n",
        "#   with open(f\"{backup_path_with_name}.pkl\", \"rb\") as f:\n",
        "#       loaded_data = pickle.load(f)\n",
        "\n",
        "#   extracted_text = loaded_data[\"extracted_text\"]\n",
        "#   video_metadata = loaded_data[\"video_metadata\"]\n",
        "#   audio_metadata = loaded_data[\"audio_metadata\"]\n",
        "#   index_db = loaded_data[\"index_db\"]\n",
        "#   return extracted_text, video_metadata, audio_metadata, index_db\n",
        "\n",
        "def load_backuped_metadata(bucket):\n",
        "    for blob in bucket.list_blobs():\n",
        "      if blob.name.startswith(\"asset/\"):\n",
        "        if blob.name.lower().endswith('.pkl'):\n",
        "          with blob.open(\"rb\") as f:\n",
        "            loaded_data = pickle.load(f)\n",
        "\n",
        "    extracted_text = loaded_data[\"extracted_text\"]\n",
        "    video_metadata = loaded_data[\"video_metadata\"]\n",
        "    audio_metadata = loaded_data[\"audio_metadata\"]\n",
        "    index_db = loaded_data[\"index_db\"]\n",
        "\n",
        "    return extracted_text, video_metadata, audio_metadata, index_db\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xTByp2cRBC2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Text Extraction"
      ],
      "metadata": {
        "id": "FRW2qZlnuNVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From all reports"
      ],
      "metadata": {
        "id": "xv5oex-9w7eI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://storage.googleapis.com/gemini-lavi-asset/img/Step1.png)"
      ],
      "metadata": {
        "id": "gMHbb17Mt_PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "extracted_text = get_text_from_pdf(bucket)"
      ],
      "metadata": {
        "id": "a65qwT9cvrkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text.head()"
      ],
      "metadata": {
        "id": "Uf-E_I_Jll4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pages per file...\",\n",
        "      extracted_text['gcs_path'].value_counts())"
      ],
      "metadata": {
        "id": "E7BAfGKXmMvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total files: ....\",\n",
        "      len(extracted_text['gcs_path'].value_counts().index))"
      ],
      "metadata": {
        "id": "b4njc-vymU0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total pages: ....\",\n",
        "      sum(extracted_text['gcs_path'].value_counts().values))"
      ],
      "metadata": {
        "id": "H1fYh9WsmkvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(extracted_text['text'][9])"
      ],
      "metadata": {
        "id": "1MfL2zeC0m4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From audio files"
      ],
      "metadata": {
        "id": "jBFcQU_Iw_rL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://storage.googleapis.com/gemini-lavi-asset/img/Step1-Audio.png)"
      ],
      "metadata": {
        "id": "ggIKizabvwlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "audio_description_extraction_prompt = \"\"\"Transcribe and analyze the audio, identifying key topic shifts or changes in focus. Divide the audio into segments based on these transitions.\n",
        "For each segment:\n",
        "* **Summarize:** Briefly describe the main topic or theme of the segment.\n",
        "* **Contextualize:** Explain how this topic fits into the broader conversation or narrative.\n",
        "* **Analyze:** Explore the significance of this topic, the perspectives presented, and any potential biases or underlying assumptions.\n",
        "* **Synthesize:** Connect this topic to other themes or ideas mentioned in the audio, highlighting relationships and overarching patterns.\n",
        "Conclude with a thematic analysis of the entire audio. Identify the most prominent themes, how they are interconnected, and the overall message or purpose of the audio.\n",
        "\"\"\"\n",
        "\n",
        "audio_metadata = get_text_from_audio(bucket, gemini_15_pro_new,\n",
        "                                     audio_description_extraction_prompt,\n",
        "                                    )"
      ],
      "metadata": {
        "id": "PclkrV3bvvUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# audio_metadata_flash = get_text_from_audio(bucket, gemini_15_flash,\n",
        "#                                      audio_description_extraction_prompt,\n",
        "#                                     )"
      ],
      "metadata": {
        "id": "3aT_kQ7xlZRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_metadata.tail()"
      ],
      "metadata": {
        "id": "29bzYDmMej0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total files: ....\",\n",
        "      len(audio_metadata['audio_gcs'].value_counts().index))"
      ],
      "metadata": {
        "id": "SU_FJRs8m4IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(audio_metadata['audio_description'][2])"
      ],
      "metadata": {
        "id": "Fmy3rPFX0QVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From video files"
      ],
      "metadata": {
        "id": "Cm8smKi6xB5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://storage.googleapis.com/gemini-lavi-asset/img/Step1_Video.png)"
      ],
      "metadata": {
        "id": "wbIyLsI4wBFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "video_description_extraction_prompt = \"\"\"Transcribe and analyze the video, intelligently segmenting it based on shifts in topic, focus, or narrative progression.\n",
        "For each identified segment:\n",
        "**Concise Summary**: Distill the core theme or message in 1-2 sentences.\n",
        "**Thematic Context**: How does this segment contribute to the overarching narrative or argument?\n",
        "**Critical Analysis**: Delve into the segment's implications, perspectives presented, and potential biases.\n",
        "**Connections**: Link this segment to other parts of the video, revealing patterns and relationships.\n",
        "\n",
        "Conclude by synthesizing the video's main themes, their interconnections, and the overarching purpose or message.\n",
        "\"\"\"\n",
        "\n",
        "video_metadata = get_text_from_video(bucket,gemini_15_pro_new,\n",
        "                                    video_description_extraction_prompt,\n",
        "                                    )\n"
      ],
      "metadata": {
        "id": "Soxp3voxwBXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "video_metadata_flash = get_text_from_video(bucket,gemini_15_flash,\n",
        "                                    video_description_extraction_prompt,\n",
        "                                    )"
      ],
      "metadata": {
        "id": "rop159VS04hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_metadata.head()"
      ],
      "metadata": {
        "id": "8o49YwAXjaHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total files: ....\",\n",
        "      len(video_metadata['video_gcs'].value_counts().index))"
      ],
      "metadata": {
        "id": "iaFCUlC41Eqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(video_metadata['video_description'][0])"
      ],
      "metadata": {
        "id": "xPbXLG1z6Ub4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Text Chunking"
      ],
      "metadata": {
        "id": "gt2OE4sJ0lz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://storage.googleapis.com/gemini-lavi-asset/img/Step2-Chunking.png\" width=\"500\" />"
      ],
      "metadata": {
        "id": "LW14JBRY4Be-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 [Why do we still do chunking? Explain ----\n",
        "# 1) show the token count\n",
        "# 2) reduce noise while search  ]\n",
        "# latency and cost consideriation - you can still do that, but would it make sense\n",
        "# Out of 5M token \"information\" -> you would still want to makes ure that the 1M that you send are the most relevant 1M\n",
        "# Chunking the Text to smaller size to make precise match with queries\n",
        "\n",
        "chunk_size =500\n",
        "extracted_text_chunk_df = split_text_into_chunks(extracted_text, 'text', chunk_size)\n",
        "video_metadata_chunk_df = split_text_into_chunks(video_metadata, 'video_description', chunk_size)\n",
        "audio_metadata_chunk_df = split_text_into_chunks(audio_metadata, 'audio_description', chunk_size)"
      ],
      "metadata": {
        "id": "s5NYr3BP0mSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text_chunk_df.head()"
      ],
      "metadata": {
        "id": "7gm2vdo86zSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(\n",
        "    extracted_text[\n",
        "        (extracted_text[\"page_number\"] == 3)\n",
        "        & (\n",
        "            extracted_text[\"gcs_path\"]\n",
        "            == \"gs://gemini-lavi-asset/production/blogpost/Google Cloud TPU blog.pdf\"\n",
        "        )\n",
        "    ][\"text\"].values[0]\n",
        ")\n"
      ],
      "metadata": {
        "id": "NCii6nc_63sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(extracted_text_chunk_df.iloc[2]['text'])"
      ],
      "metadata": {
        "id": "0wVtVVtO6vUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(extracted_text_chunk_df.iloc[3]['text'])"
      ],
      "metadata": {
        "id": "Y0snwU3T72w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(extracted_text_chunk_df.iloc[4]['text'])"
      ],
      "metadata": {
        "id": "V5MHqpZv73-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Embedding"
      ],
      "metadata": {
        "id": "ewg7WvfC48-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/gemini-lavi-asset/img/Step2-Chunking_embedding.png\" width=\"500\" />"
      ],
      "metadata": {
        "id": "xw8UmaTr49Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Step 3\n",
        "# Building Embeddings of the text\n",
        "\n",
        "extracted_text_chunk_df['embeddings'] = extracted_text_chunk_df['text'].apply(lambda x: get_text_embeddings([x]))\n",
        "video_metadata_chunk_df['embeddings'] = video_metadata_chunk_df['video_description'].apply(lambda x: get_text_embeddings([x]))\n",
        "audio_metadata_chunk_df['embeddings'] = audio_metadata_chunk_df['audio_description'].apply(lambda x: get_text_embeddings([x]))"
      ],
      "metadata": {
        "id": "sZUD_RSB49lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text_chunk_df.head()"
      ],
      "metadata": {
        "id": "auswTfut8Txi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_metadata_chunk_df.head()"
      ],
      "metadata": {
        "id": "kG9uox928Y9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_metadata_chunk_df.head()"
      ],
      "metadata": {
        "id": "QAweKRqr9Zb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Building Index"
      ],
      "metadata": {
        "id": "CWhvcZuG4tJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4 Building final metadata and index for the vector db\n",
        "# Building index\n",
        "\n",
        "extracted_text_chunk_df['index'] = extracted_text_chunk_df['page_number'].astype(str)+ \"_\"+extracted_text_chunk_df['text_type']+ \"_\" + extracted_text_chunk_df.index.astype(str)\n",
        "video_metadata_chunk_df['index'] = video_metadata_chunk_df['video_type']+ \"_\" + video_metadata_chunk_df.index.astype(str)\n",
        "audio_metadata_chunk_df['index'] = audio_metadata_chunk_df['audio_type']+ \"_\" + audio_metadata_chunk_df.index.astype(str)\n",
        "\n",
        "#Adding source to identify type of file\n",
        "print(\"Adding source type in the metadata......\")\n",
        "extracted_text_chunk_df['source'] = \"text_based\"\n",
        "video_metadata_chunk_df['source'] = \"video_based\"\n",
        "audio_metadata_chunk_df['source'] = \"audio_based\"\n",
        "\n",
        "#Building index data\n",
        "print(\"Building index data from the metadata......\")\n",
        "index_db = pd.concat([extracted_text_chunk_df[['index','source','embeddings']],\n",
        "          video_metadata_chunk_df[['index','source','embeddings']],\n",
        "          audio_metadata_chunk_df[['index','source','embeddings']]\n",
        "                      ],\n",
        "        axis=0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "37w2tpEr4uNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_db.head()"
      ],
      "metadata": {
        "id": "ZrKxgl7b-x_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text_chunk_df.head()"
      ],
      "metadata": {
        "id": "IF2TaD2D-2AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_metadata_chunk_df.head()"
      ],
      "metadata": {
        "id": "Ol0xbOdC--Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_metadata_chunk_df.head()"
      ],
      "metadata": {
        "id": "DnIEEv0g_A1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backing up the metadata"
      ],
      "metadata": {
        "id": "CIPTwz5Q5W46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# backup_metadata_in_pickle(extracted_text,\n",
        "#                           video_metadata,\n",
        "#                           audio_metadata,\n",
        "#                           index_db,\n",
        "#                           output_path_with_name=\"/content/metadata\"\n",
        "#                           )"
      ],
      "metadata": {
        "id": "4AFtaXKe5XRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download documents and images used in this notebook - will take ~30 sec\n",
        "!gsutil -m -q rsync -r gs://gemini-lavi-asset/asset/ .\n",
        "print(\"Download completed\")"
      ],
      "metadata": {
        "id": "_FqlPM8u_fHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracted_text, video_metadata, audio_metadata, index_db = load_backuped_metadata(\"/content/metadata\")\n",
        "import pickle\n",
        "extracted_text, video_metadata, audio_metadata, index_db = load_backuped_metadata(bucket)"
      ],
      "metadata": {
        "id": "r71FNCtuMZhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text.head()"
      ],
      "metadata": {
        "id": "Q1PnsWveBtlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_metadata.head()"
      ],
      "metadata": {
        "id": "KK0681vEJnUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_metadata.head()"
      ],
      "metadata": {
        "id": "rG6NE4AxqFPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_db.head()"
      ],
      "metadata": {
        "id": "hC7KSXZ6qG8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gemini_15_pro_new.count_tokens('-'.join(extracted_text['text'])))"
      ],
      "metadata": {
        "id": "P3-Rf8vvJSZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gemini_15_pro_new.count_tokens('-'.join(video_metadata['video_description'])))"
      ],
      "metadata": {
        "id": "cvcmvUdKp4ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gemini_15_pro_new.count_tokens('-'.join(audio_metadata['audio_description'])))"
      ],
      "metadata": {
        "id": "F6y2MiPQp4v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retreival & Generation"
      ],
      "metadata": {
        "id": "AZ90c_6JKMQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helper Functions\n",
        "\n",
        "def get_cosine_score(\n",
        "    dataframe: pd.DataFrame, column_name: str, input_text_embd: np.ndarray\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Calculates the cosine similarity between the user query embedding and the dataframe embedding for a specific column.\n",
        "\n",
        "    Args:\n",
        "        dataframe: The pandas DataFrame containing the data to compare against.\n",
        "        column_name: The name of the column containing the embeddings to compare with.\n",
        "        input_text_embd: The NumPy array representing the user query embedding.\n",
        "\n",
        "    Returns:\n",
        "        The cosine similarity score (rounded to two decimal places) between the user query embedding and the dataframe embedding.\n",
        "    \"\"\"\n",
        "    if dataframe[column_name]:\n",
        "      text_cosine_score = round(np.dot(dataframe[column_name], input_text_embd), 2)\n",
        "      return text_cosine_score\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "def get_timestamp_with_milliseconds():\n",
        "    \"\"\"Gets the current time as a timestamp string with milliseconds.\"\"\"\n",
        "\n",
        "    now = datetime.now(timezone.utc)  # Get current UTC time with timezone awareness\n",
        "    timestamp_str = now.strftime(\"%Y-%m-%d-%H:%M:%S.%f\")[:-3]  # Format with milliseconds\n",
        "\n",
        "    return timestamp_str\n",
        "\n",
        "def get_pdf_from_matched_index(text_index):\n",
        "  # print(\"Unique Text index: \", unique_text_cit)\n",
        "  storage_client = storage.Client(project='kaggle-on-gcp')\n",
        "  bucket = storage_client.bucket(\"gemini-lavi-asset\")\n",
        "\n",
        "  selected_file = {}\n",
        "  gcs_path = extracted_text[extracted_text['index']==text_index]['gcs_path'].values[0].split(\"//\")[1]\n",
        "  gcs_path = \"/\".join(gcs_path.split(\"/\")[1:])\n",
        "  page_num = extracted_text[extracted_text['index']==text_index]['page_number'].values[0]\n",
        "  selected_file[gcs_path] = int(page_num)\n",
        "  # print(selected_file)\n",
        "  pdf_object_part_list = []\n",
        "  for blob in bucket.list_blobs(prefix=\"production/\"):\n",
        "      if blob.name in selected_file:\n",
        "        pdf_content = BytesIO(blob.download_as_bytes())\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_content)\n",
        "        pdf_writer = PyPDF2.PdfWriter()\n",
        "        pdf_writer.add_page(pdf_reader.pages[selected_file[blob.name]])\n",
        "\n",
        "        # pdf_writer.add_page(pdf_reader.pages[selected_file[blob.name]])\n",
        "        # Create a BytesIO buffer to hold the output PDF\n",
        "        output_buffer = BytesIO()\n",
        "\n",
        "        # Write the PDF to the buffer\n",
        "        pdf_writer.write(output_buffer)\n",
        "        output_buffer.seek(0)  # Reset buffer position to the beginning\n",
        "\n",
        "        # Upload the buffer content to GCS\n",
        "        new_blob_name = f\"\"\"temp/{blob.name.split(\"/\")[-1]}_selected_pages_{selected_file[blob.name]}_{get_timestamp_with_milliseconds()}.pdf\"\"\"\n",
        "        new_blob = bucket.blob(new_blob_name)\n",
        "        # print(new_blob_name)\n",
        "        # print(new_blob)\n",
        "        new_blob.upload_from_string(output_buffer.getvalue(), content_type=\"application/pdf\")\n",
        "        gcs_path = \"gs://\"+blob.bucket.name+\"/\"+new_blob_name\n",
        "        pdf_object_part_list.extend([\"filename: \",gcs_path, Part.from_uri(uri=gcs_path, mime_type=\"application/pdf\")])\n",
        "        # print(f\"Uploaded selected pages to: {new_blob_name}\")\n",
        "\n",
        "  # print(\"Created temp pdf's to address the query in GCS.....\")\n",
        "  return pdf_object_part_list\n",
        "\n",
        "def get_gemini_content_list(query, vector_db, top_n_cosine_scores):\n",
        "  instruction = \"\"\"Task: Answer the following questions in detail, providing clear reasoning and evidence from the context files in bullet points.\n",
        "  Instructions:\n",
        "\n",
        "  1. **Analyze:** Carefully examine the provided images and text context.\n",
        "  2. **Synthesize:** Integrate information from both the visual and textual elements.\n",
        "  3. **Reason:**  Deduce logical connections and inferences to address the question.\n",
        "  4. **Respond:** Provide a concise, accurate answer in the following format:\n",
        "\n",
        "    * **Question:** [Question]\n",
        "    * **Answer:** [Direct response to the question]\n",
        "    * **Explanation:** [Bullet-point reasoning steps if applicable]\n",
        "    * **Source** [name of the file, page, image from where the information is citied]\n",
        "\n",
        "  5. **Ambiguity:** If the context is insufficient to answer, respond \"Not enough context to answer.\"\n",
        "  \"\"\"\n",
        "  gemini_content = [instruction,\"Questions:\", query,\n",
        "  \"Contexual Files:\" ]\n",
        "\n",
        "  vector_db_sample = vector_db.iloc[top_n_cosine_scores]\n",
        "  uri_track = []\n",
        "  for index, row in vector_db_sample.iterrows():\n",
        "    if row['source'] == 'video_based':\n",
        "      gcs_path = video_metadata[video_metadata['index']==row['index']]['video_gcs'].values[0]\n",
        "      mime = 'video/mp4'\n",
        "      if gcs_path not in uri_track:\n",
        "        uri_track.append(gcs_path)\n",
        "        gemini_content.extend([\"filename: \",gcs_path,Part.from_uri(uri=gcs_path, mime_type= mime)])\n",
        "\n",
        "    elif row['source'] == 'audio_based':\n",
        "      gcs_path = audio_metadata[audio_metadata['index']==row['index']]['audio_gcs'].values[0]\n",
        "      mime = 'audio/mpeg'\n",
        "      if gcs_path not in uri_track:\n",
        "        uri_track.append(gcs_path)\n",
        "        gemini_content.extend([\"filename: \",gcs_path, Part.from_uri(uri=gcs_path, mime_type= mime)])\n",
        "\n",
        "    elif row['source'] == 'text_based':\n",
        "      pdf_object_part_list = get_pdf_from_matched_index(row['index'])\n",
        "      # print(\"Some files are temp uploaded to gcs to support the query....\")\n",
        "      gemini_content.extend(pdf_object_part_list)\n",
        "\n",
        "    else:\n",
        "      print (\"Something has gone wrong......\")\n",
        "\n",
        "  return gemini_content\n",
        "\n",
        "def get_gemini_response(model, generation_config=None,\n",
        "                        safety_settings=None,\n",
        "                        uri_path=None,mime_type=None, prompt=None):\n",
        "  if not generation_config:\n",
        "    generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 1,\n",
        "      \"top_p\": 0.95,\n",
        "    }\n",
        "\n",
        "  if not safety_settings:\n",
        "    safety_settings = {\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    }\n",
        "\n",
        "  responses = model.generate_content(prompt,\n",
        "      generation_config=generation_config,\n",
        "      safety_settings=safety_settings,\n",
        "      stream=True,\n",
        "  )\n",
        "  final_response = []\n",
        "  for response in responses:\n",
        "    try:\n",
        "      final_response.append(response.text)\n",
        "    except ValueError:\n",
        "      # print(\"Something is blocked...\")\n",
        "      final_response.append(\"blocked\")\n",
        "\n",
        "  return \"\".join(final_response)\n",
        "\n",
        "def get_answer(query,vector_db, model, top_n=5):\n",
        "  query_embedding = get_text_embeddings([query])\n",
        "  #Find score\n",
        "  cosine_scores = vector_db.apply(\n",
        "              lambda x: get_cosine_score(x, 'embeddings', query_embedding),\n",
        "              axis=1,\n",
        "          )\n",
        "  # Remove same image comparison score when user image is matched exactly with metadata image\n",
        "  # cosine_scores = cosine_scores[cosine_scores < 1.00000000]\n",
        "  # Get top N cosine scores and their indices\n",
        "  top_n_cosine_scores = cosine_scores.nlargest(top_n).index.tolist()\n",
        "  top_n_cosine_values = cosine_scores.nlargest(top_n).values.tolist()\n",
        "\n",
        "  citations = vector_db.iloc[top_n_cosine_scores]\n",
        "  # citations['score'] = top_n_cosine_scores\n",
        "  citations.loc[:, 'score'] = top_n_cosine_values\n",
        "  citations = citations[['index','source','score']]\n",
        "\n",
        "  # print(citations)\n",
        "  gemini_content = get_gemini_content_list(query, vector_db, top_n_cosine_scores)\n",
        "\n",
        "  response  =  get_gemini_response(model=model, prompt=gemini_content)\n",
        "  return([response, gemini_content, citations])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xSCCOaO6KB-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"- What is the role of AI in accelerating the progress of UN's sustainable development goals\n",
        "- What specific commitments and initiatives demonstrate Google's collaboration with the UN on AI for good?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8DPseIv2CGzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response, gemini_content, citation = get_answer(query, index_db, gemini_15_pro_new,top_n=5)\n",
        "rich_Markdown(response)"
      ],
      "metadata": {
        "id": "y5aixdfTCMB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response, gemini_content, citation = get_answer(query, index_db, gemini_15_flash,top_n=5)\n",
        "rich_Markdown(response)"
      ],
      "metadata": {
        "id": "YY6OzWWYF5PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_content"
      ],
      "metadata": {
        "id": "LHAJGVbPCOE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "citation"
      ],
      "metadata": {
        "id": "jTgBScMmCQDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# time.sleep(30)\n",
        "query = \"How does Gemini 1.5 long context works with video, images, text and code? Give detail examples that Google showed?\"\n",
        "response, gemini_content, citation = get_answer(query, index_db, gemini_15_pro_new,top_n=5)\n",
        "rich_Markdown(response)"
      ],
      "metadata": {
        "id": "ZW1YYsnKGWGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "citation"
      ],
      "metadata": {
        "id": "XEvWtOVGGu_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# time.sleep(30)\n",
        "query = \"What are key achievement for Google Cloud in terms of training LLMs using their TPUs?\"\n",
        "response, gemini_content, citation = get_answer(query, index_db, gemini_15_pro_new,top_n=5)\n",
        "rich_Markdown(response)"
      ],
      "metadata": {
        "id": "WV0jiOurGZzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "citation"
      ],
      "metadata": {
        "id": "O1pFO6PsGvYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# time.sleep(30)\n",
        "query = \"what is the emfu for bf16 and 128b parameter model with 1 tpu v5e pod? Cite the table and page number and explain the significance of the results\"\n",
        "response, gemini_content, citation = get_answer(query, index_db, gemini_15_pro_new,top_n=5)\n",
        "rich_Markdown(response)"
      ],
      "metadata": {
        "id": "iLUlwO1lGiRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "citation"
      ],
      "metadata": {
        "id": "NAHjBMylGvzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}